# This workflow bootstraps the global Terraform backend.
# Steps:
name: Bootstrap Backend Pipeline
description: Bootstraps the global Terraform backend (S3, DynamoDB, OIDC) and stores backend configuration in AWS SSM Parameter Store.
on:
  workflow_dispatch: # Manual trigger so you only run bootstrap when needed
    inputs:
      region:
        description: "Region to deploy to (i.e. us-east-1, eu-west-2, etc.)"
        type: string
        required: true

permissions:
  id-token: write # Required for github oidc authentication with AWS
  contents: read # Allow repository contents to be checked out

jobs:
  bootstrap-global:
    name: Bootstrap Global Terraform Backend
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: global-backend

    steps:
      # 1. Checkout the repo
      - name: Checkout
        uses: actions/checkout@v4

      # 2. Configure AWS credentials using github environment secrets
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ github.event.inputs.region }}
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      # 3. Install Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.12.2" # Pin to specific version

      # 4. Initialize Terraform locally on github runner
      - name: Terraform Init
        run: terraform init -backend=false

      # 5. Apply global backend infrastructure
      # - Creates S3 bucket for state
      # - Creates DynamoDB table for state locking
      # - Creates IAM OIDC provider + IAM policy
      - name: Apply Global Backend
        run: terraform apply -var-file=global.tfvars -var="aws_account_id=${{ vars.AWS_ACCOUNT_ID }}" -auto-approve

      # 6. Export Terraform outputs to JSON file
      - name: Export Outputs
        run: terraform output -json > tf_outputs.json

      # 7. Install jq for parsing JSON outputs
      - name: Install jq
        run: sudo apt-get install -y jq

      # 8. Store global backend bucket, table and region in SSM Parameter Store
      # - This lets next workflow get the backend config dynamically
      - name: Store Backend Config in AWS SSM
        run: |
          STATE_BUCKET=$(jq -r '.state_bucket_name.value' tf_outputs.json)
          STATE_TABLE=$(jq -r '.state_table_name.value' tf_outputs.json)
          REGION=$(jq -r '.region.value' tf_outputs.json)
          DEV_LAMBDA_BUCKET=$(jq -r '.lambda_code_bucket_dev_name.value' tf_outputs.json)
          TEST_LAMBDA_BUCKET=$(jq -r '.lambda_code_bucket_test_name.value' tf_outputs.json)
          PROD_LAMBDA_BUCKET=$(jq -r '.lambda_code_bucket_prod_name.value' tf_outputs.json)

          aws ssm put-parameter --name "/tf/global-backend/state-bucket" --value "$STATE_BUCKET" --type String
          aws ssm put-parameter --name "/tf/global-backend/state-table"  --value "$STATE_TABLE"  --type String
          aws ssm put-parameter --name "/tf/global-backend/region" --value "$REGION" --type String
          aws ssm put-parameter --name "/tf/global-backend/lambda-bucket-dev" --value "$DEV_LAMBDA_BUCKET" --type String
          aws ssm put-parameter --name "/tf/global-backend/lambda-bucket-test" --value "$TEST_LAMBDA_BUCKET" --type String
          aws ssm put-parameter --name "/tf/global-backend/lambda-bucket-prod" --value "$PROD_LAMBDA_BUCKET" --type String
